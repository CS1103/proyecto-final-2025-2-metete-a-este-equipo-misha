# Arquitectura del Proyecto PONG AI - Epic 3

## ğŸ“‹ DescripciÃ³n General

Este documento detalla la arquitectura y diseÃ±o del framework de redes neuronales implementado en C++20 para el proyecto PONG AI, focusing en el Epic 3 (AplicaciÃ³n y DocumentaciÃ³n).

## ğŸ—ï¸ Estructura de Carpetas

```
include/utec/
â”œâ”€â”€ algebra/                   # Ãlgebra Lineal (Epic 1 - No modificar)
â”‚   â””â”€â”€ tensor.h              # Tensor<T, Rank> - Arrays multidimensionales
â”œâ”€â”€ nn/                        # Red Neuronal (Epic 2 - No modificar)
â”‚   â”œâ”€â”€ nn_interfaces.h       # Interfaces: ILayer<T>, IOptimizer<T>, ILoss<T>
â”‚   â”œâ”€â”€ nn_dense.h            # Capas densas (fully connected)
â”‚   â”œâ”€â”€ nn_activation.h       # Funciones de activaciÃ³n (ReLU, Sigmoid)
â”‚   â”œâ”€â”€ nn_loss.h             # Funciones de pÃ©rdida (MSE, BCE)
â”‚   â”œâ”€â”€ nn_optimizer.h        # Optimizadores (SGD, Adam)
â”‚   â””â”€â”€ neural_network.h      # Clase principal de red neuronal
â””â”€â”€ agent/                     # Agentes y Aplicaciones (Epic 3)
    â””â”€â”€ PongAgent.h           # Agente de Pong + Ambiente de simulaciÃ³n
```

## ğŸ”‘ Componentes Principales

### 1. **Tensor<T, Rank>** (Epic 1)
- **UbicaciÃ³n**: `include/utec/algebra/tensor.h`
- **DescripciÃ³n**: Arrays multidimensionales genÃ©ricos en C++20
- **CaracterÃ­sticas**:
  - Acceso variÃ¡dico: `tensor(i, j, k, ...)`
  - Broadcasting automÃ¡tico para operaciones
  - Operaciones de matriz: transposiciÃ³n, multiplicaciÃ³n
  - Iteradores eficientes para recorrido secuencial

**MÃ©todos clave**:
```cpp
Tensor<T, N> tensor(d1, d2, ..., dN);  // Constructor
T& operator()(idx...);                  // Acceso
std::array<size_t, N> shape();         // Dimensiones
Tensor<T,2> matrix_product(A, B);      // MultiplicaciÃ³n matricial
Tensor<T,2> transpose(M);               // TransposiciÃ³n
```

### 2. **Interfaz de Capas** (Epic 2)

#### ILayer<T>
- **UbicaciÃ³n**: `include/utec/nn/nn_interfaces.h`
- **MÃ©todos virtuales**:
  ```cpp
  virtual Tensor<T,2> forward(const Tensor<T,2>& x) = 0;
  virtual Tensor<T,2> backward(const Tensor<T,2>& gradient) = 0;
  virtual void update_params(IOptimizer<T>& optimizer) {}
  ```

#### Capas Implementadas

**Dense (Fully Connected)**
- **UbicaciÃ³n**: `include/utec/nn/nn_dense.h`
- **ParÃ¡metros**: pesos (W) y sesgos (b)
- **Forward**: `Z = XÂ·W + b`
- **Backward**: Calcula gradientes âˆ‡W, âˆ‡b, âˆ‡X
- **InicializaciÃ³n**: Xavier por defecto

```cpp
Dense<float> layer(input_dim, output_dim);
auto output = layer.forward(input);
auto grad_input = layer.backward(grad_output);
```

**ReLU (Rectified Linear Unit)**
- **UbicaciÃ³n**: `include/utec/nn/nn_activation.h`
- **Forward**: `y = max(0, x)`
- **Backward**: `dy/dx = 1 si x > 0, else 0`

**Sigmoid**
- **Forward**: `y = 1 / (1 + e^(-x))`
- **Backward**: `dy/dx = Ïƒ(x) * (1 - Ïƒ(x))`

### 3. **Funciones de PÃ©rdida** (Epic 2)

#### MSELoss (Mean Squared Error)
- **UbicaciÃ³n**: `include/utec/nn/nn_loss.h`
- **FÃ³rmula**: `L = (1/N) * Î£(Å· - y)Â²`
- **Gradiente**: `dL/dÅ· = 2(Å· - y)/N`
- **Uso**: Problemas de regresiÃ³n

```cpp
MSELoss<float> loss(predictions, targets);
float loss_value = loss.loss();
auto gradient = loss.loss_gradient();
```

#### BCELoss (Binary Cross Entropy)
- **FÃ³rmula**: `L = -(1/N) * Î£[y*log(p) + (1-y)*log(1-p)]`
- **Gradiente**: `dL/dÅ· = (p - y)/(p*(1-p)*N)`
- **Uso**: ClasificaciÃ³n binaria

### 4. **Optimizadores** (Epic 2)

#### SGD (Stochastic Gradient Descent)
- **UbicaciÃ³n**: `include/utec/nn/nn_optimizer.h`
- **ActualizaciÃ³n**: `Î¸ = Î¸ - Î±âˆ‡L`
- **ParÃ¡metros**: learning_rate (Î±)

```cpp
SGD<float> optimizer(0.01f);
optimizer.update(weights, gradients);
```

#### Adam (Adaptive Moment Estimation)
- **CaracterÃ­sticas**: Momentos adaptivos de primer y segundo orden
- **ParÃ¡metros**: 
  - `learning_rate` (tÃ­picamente 0.001)
  - `beta1` = 0.9 (decaimiento del primer momento)
  - `beta2` = 0.999 (decaimiento del segundo momento)
  - `epsilon` = 1e-8 (estabilidad numÃ©rica)

```cpp
Adam<float> optimizer(0.001f, 0.9f, 0.999f, 1e-8f);
optimizer.update(weights, gradients);
optimizer.step();
```

### 5. **Red Neuronal** (Epic 2/3)

#### NeuralNetwork<T>
- **UbicaciÃ³n**: `include/utec/nn/neural_network.h`
- **CaracterÃ­sticas**:
  - ComposiciÃ³n flexible de capas
  - Entrenamiento con mini-batches
  - Early stopping
  - MÃ©tricas de evaluaciÃ³n

**MÃ©todos principales**:

```cpp
NeuralNetwork<float> net;

// Agregar capas
net.add_layer(std::make_unique<Dense<float>>(2, 4));
net.add_layer(std::make_unique<ReLU<float>>());

// Forward pass (predicciÃ³n)
auto output = net.forward(input);

// Entrenamiento bÃ¡sico (MSE + SGD por defecto)
float final_loss = net.train(X, Y, epochs, learning_rate);

// Entrenamiento avanzado (con early stopping)
auto metrics = net.train_advanced(
    X, Y,                    // Datos de entrada y salida
    max_epochs,              // NÃºmero mÃ¡ximo de Ã©pocas
    learning_rate,           // Tasa de aprendizaje
    patience,                // Ã‰pocas sin mejora antes de parar
    min_delta                // Mejora mÃ­nima considerada como progreso
);

// EvaluaciÃ³n en datos de prueba
auto eval = net.evaluate(X_test, Y_test);
// Retorna: test_loss, accuracy, mean_absolute_error
```

**Estructuras de MÃ©tricas**:

```cpp
// TrainingMetrics
struct TrainingMetrics<T> {
    size_t epochs_trained;              // Ã‰pocas ejecutadas
    T final_loss;                       // PÃ©rdida final
    T best_loss;                        // Mejor pÃ©rdida alcanzada
    bool converged;                     // Â¿ConvergiÃ³ tempranamente?
    std::vector<T> loss_history;        // HistÃ³rico de pÃ©rdida por Ã©poca
};

// EvaluationMetrics
struct EvaluationMetrics<T> {
    T test_loss;                        // MSE en datos de prueba
    T accuracy;                         // PrecisiÃ³n (0-1)
    T mean_absolute_error;              // Error absoluto promedio
};
```

### 6. **Agente de Pong** (Epic 3)

#### PongAgent<T>
- **UbicaciÃ³n**: `include/utec/agent/PongAgent.h`
- **DescripciÃ³n**: Agente que aprende a jugar Pong usando una red neuronal

```cpp
struct State {
    float ball_x, ball_y;     // PosiciÃ³n de la bola
    float paddle_y;            // PosiciÃ³n de la paleta
};

PongAgent<float> agent(neural_network);
int action = agent.act(state);  // Retorna: -1 (arriba), 0 (quedo), 1 (abajo)
```

#### EnvGym (Simulador de Pong)
- **MÃ©todos**:
  ```cpp
  State reset();                              // Reinicia el juego
  State step(action, reward, done);           // Ejecuta una acciÃ³n
  ```
- **Recompensas**:
  - `+1.0` cuando golpea la bola exitosamente
  - `+0.5` cuando la bola llega al lado del oponente
  - `-1.0` cuando falla y pierde

## ğŸ“Š Flujo de Entrenamiento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. PREPARACIÃ“N DE DATOS                             â”‚
â”‚   - Crear tensores X (entrada) e Y (salida)        â”‚
â”‚   - Normalizar/escalar si es necesario              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. DEFINICIÃ“N DE ARQUITECTURA                       â”‚
â”‚   - add_layer(Dense)                                â”‚
â”‚   - add_layer(ReLU/Sigmoid)                         â”‚
â”‚   - Repetir segÃºn sea necesario                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ENTRENAMIENTO (por cada Ã©poca)                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚ Para cada mini-batch:                   â”‚      â”‚
â”‚   â”‚  a) Forward pass: Å· = net(x)            â”‚      â”‚
â”‚   â”‚  b) Calcular pÃ©rdida: L = loss(Å·, y)   â”‚      â”‚
â”‚   â”‚  c) Backward pass: âˆ‡L                   â”‚      â”‚
â”‚   â”‚  d) Actualizar parÃ¡metros: Î¸ -= Î±âˆ‡L    â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                     â”‚
â”‚   Si: early_stopping activado                      â”‚
â”‚   â”œâ”€ Evaluar en validaciÃ³n                         â”‚
â”‚   â”œâ”€ Si no mejora en 'patience' Ã©pocas â†’ STOP      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. EVALUACIÃ“N Y PREDICCIÃ“N                          â”‚
â”‚   - evaluate(X_test, Y_test)                        â”‚
â”‚   - forward(X_new)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Algoritmos Implementados

### Forward Propagation
Para cada capa i:
```
a[i] = Ïƒ(z[i])  donde z[i] = a[i-1] Â· W[i] + b[i]
```

### Backward Propagation
Para cada capa i (de atrÃ¡s hacia adelante):
```
dz[i] = Ïƒ'(z[i]) * da[i]
dW[i] = (1/m) * a[i-1]áµ€ Â· dz[i]
db[i] = (1/m) * Î£ dz[i]  (suma sobre muestras)
da[i-1] = dz[i] Â· W[i]áµ€
```

### ActualizaciÃ³n de ParÃ¡metros (SGD)
```
W = W - Î± * dW
b = b - Î± * db
```

### ActualizaciÃ³n de ParÃ¡metros (Adam)
```
m_t = Î²1 * m_{t-1} + (1-Î²1) * g_t
v_t = Î²2 * v_{t-1} + (1-Î²2) * g_tÂ²
mÌ‚_t = m_t / (1 - Î²1^t)
vÌ‚_t = v_t / (1 - Î²2^t)
Î¸_{t+1} = Î¸_t - Î± * mÌ‚_t / (âˆšvÌ‚_t + Îµ)
```

## ğŸ“ˆ Complejidad Computacional

| OperaciÃ³n | Complejidad | DescripciÃ³n |
|-----------|------------|------------|
| Forward (Dense) | O(nÂ·m) | n inputs, m outputs |
| Backward (Dense) | O(nÂ·m) | Gradientes de pesos |
| Matrix Product | O(nÂ·mÂ·k) | MultiplicaciÃ³n matricial NxM por MxK |
| MSELoss | O(n) | n predicciones |
| Adam Update | O(n) | n parÃ¡metros |

## ğŸ§ª Pruebas

### Test Files
- `tests/test_tensor.cpp` - Pruebas de operaciones Tensor
- `tests/test_neural_network.cpp` - Pruebas de capas y funciones de pÃ©rdida
- `tests/test_agent_env.cpp` - Pruebas del agente Pong

### Ejemplos
- `examples/train_xor.cpp` - Entrenamiento en problema XOR
- `examples/train_pong_agent.cpp` - Entrenamiento del agente Pong

## ğŸš€ CompilaciÃ³n y EjecuciÃ³n

```bash
# Compilar
cmake --build cmake-build-debug

# Ejecutar programa principal
./PONG_AI

# Ejecutar ejemplo XOR
./train_xor

# Ejecutar tests
./test_tensor
./test_neural_network
./test_agent_env
```

## ğŸ“ Consideraciones de DiseÃ±o

### 1. **GenÃ©ricos (Templates)**
- Todo es templado en tipo `T` (float, double, etc.)
- Permite flexibilidad en precisiÃ³n numÃ©rica

### 2. **Polimorfismo Virtual**
- ILayer<T>, IOptimizer<T>, ILoss<T> como interfaces
- Permite agregar nuevas capas/optimizadores fÃ¡cilmente

### 3. **Smart Pointers**
- `std::unique_ptr` para gestiÃ³n automÃ¡tica de memoria
- Evita memory leaks

### 4. **Move Semantics**
- `add_layer(std::make_unique<...>())` transfiere propiedad
- Eficiente sin copias innecesarias

### 5. **Broadcasting**
- Operaciones automÃ¡ticas Tensor+Tensor y Tensor+Escalar
- Simplifica cÃ³digo de capas

## ğŸ¯ Limitaciones y Futuras Mejoras

### Actuales
- Operaciones 2D principalmente (tablas de datos)
- Sin paralelizaciÃ³n explÃ­cita (OpenMP preparado)
- Mini-batch size fijo (32)

### Futuras
- [ ] Operaciones SIMD vectorizadas
- [ ] GPU support (CUDA)
- [ ] Dropout, BatchNorm
- [ ] Modelos pre-entrenados
- [ ] SerializaciÃ³n (guardar/cargar modelos)

## ğŸ“š Referencias BibliogrÃ¡ficas

Ver `docs/BIBLIOGRAFIA.md` para detalles de fuentes acadÃ©micas.

